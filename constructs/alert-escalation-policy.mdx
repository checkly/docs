---
title: 'Alert Escalation Policy Construct'
description: 'Learn how to configure alert escalation policies with the Checkly CLI.'
sidebarTitle: 'Alert Escalation Policy'
---

Use AlertEscalationPolicy to control when and how often you receive notifications when checks start failing, degrade, or recover. This helps you fine-tune your alerting to reduce noise and ensure timely notifications.

<Info>
Learn more about alert escalation policies in the [Alert Settings documentation](/docs/communicate/alerts/configuration).
</Info>

## `AlertEscalationPolicy` Structure

<CodeGroup>

```ts Run-Based Escalation
import { ApiCheck, AlertEscalationBuilder } from 'checkly/constructs'

new ApiCheck('run-based-alert-check', {
  name: 'Check With Run-Based Escalation',
  alertEscalationPolicy: AlertEscalationBuilder.runBasedEscalation(
    2, // Alert after 2 consecutive failures
    { interval: 5, amount: 2 }, // Send 2 reminders, 5 minutes apart
    { enabled: true, percentage: 50 } // Alert if 50% of parallel runs fail
  ),
  request: {
    method: 'GET',
    url: 'https://api.example.com/health'
  }
})
```

```ts Time-Based Escalation
import { ApiCheck, AlertEscalationBuilder } from 'checkly/constructs'

new ApiCheck('time-based-alert-check', {
  name: 'Check With Time-Based Escalation',
  alertEscalationPolicy: AlertEscalationBuilder.timeBasedEscalation(
    10, // Alert after 10 minutes of failures
    { interval: 15, amount: 3 }, // Send 3 reminders, 15 minutes apart
    { enabled: false, percentage: 30 } // Parallel run threshold disabled
  ),
  request: {
    method: 'GET',
    url: 'https://api.example.com/critical-endpoint'
  }
})
```

</CodeGroup>

## `AlertEscalationPolicy` Configuration

AlertEscalationPolicy objects are built using the `AlertEscalationBuilder` which provides helper methods for different escalation strategies:

| Method | Description | Parameters |
|--------|-------------|------------|
| `runBasedEscalation()` | Alert after N consecutive failed runs | `(failedRuns, reminders, parallelRunFailureThreshold)` |
| `timeBasedEscalation()` | Alert after N minutes of continuous failures | `(minutesFailing, reminders, parallelRunFailureThreshold)` |

## Builder Methods

<ResponseField name="runBasedEscalation" type="function" required>
Creates an alert escalation policy that triggers after a specified number of consecutive failed runs.

### Usage
```ts
AlertEscalationBuilder.runBasedEscalation(failedRuns, reminders, parallelRunFailureThreshold)
```

### Parameters
| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `failedRuns` | `number` | ✅ | Number of consecutive failed runs before alerting |
| `reminders` | `object` | ❌ | Reminder notification configuration |
| `parallelRunFailureThreshold` | `object` | ❌ | Parallel run failure percentage threshold |

### Examples

<CodeGroup>

```ts Immediate Alert
// Alert immediately on first failure
const immediateAlert = AlertEscalationBuilder.runBasedEscalation(
  1, // Alert after 1 failed run
  { interval: 5, amount: 0 }, // No reminders
  { enabled: false, percentage: 50 }
)

new ApiCheck('critical-service-check', {
  name: 'Critical Service Check',
  alertEscalationPolicy: immediateAlert,
  request: {
    method: 'GET',
    url: 'https://api.example.com/critical'
  }
})
```

```ts Conservative Alert
// Wait for multiple failures before alerting
const conservativeAlert = AlertEscalationBuilder.runBasedEscalation(
  5, // Alert after 5 consecutive failures
  { interval: 30, amount: 2 }, // 2 reminders, 30 minutes apart
  { enabled: true, percentage: 80 } // Only if 80% of parallel runs fail
)

new ApiCheck('flaky-service-check', {
  name: 'Flaky Service Check',
  alertEscalationPolicy: conservativeAlert,
  locations: ['us-east-1', 'eu-west-1', 'ap-southeast-1'],
  runParallel: true,
  request: {
    method: 'GET',
    url: 'https://api.example.com/sometimes-flaky'
  }
})
```

```ts High Frequency
// For very frequent checks
const highFrequencyAlert = AlertEscalationBuilder.runBasedEscalation(
  10, // Alert after 10 failures (about 5 minutes with 30s frequency)
  { interval: 5, amount: 5 }, // 5 reminders, 5 minutes apart
  { enabled: true, percentage: 70 }
)

new ApiCheck('high-frequency-check', {
  name: 'High Frequency Health Check',
  frequency: Frequency.EVERY_30S,
  alertEscalationPolicy: highFrequencyAlert,
  locations: ['us-east-1', 'eu-west-1'],
  runParallel: true,
  request: {
    method: 'GET',
    url: 'https://api.example.com/health'
  }
})
```

</CodeGroup>

**Use cases**: Immediate alerting, noise reduction for flaky services, high-frequency monitoring.
</ResponseField>

<ResponseField name="timeBasedEscalation" type="function" required>
Creates an alert escalation policy that triggers after a specified duration of continuous failures.

### Usage
```ts
AlertEscalationBuilder.timeBasedEscalation(minutesFailing, reminders, parallelRunFailureThreshold)
```

### Parameters
| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `minutesFailing` | `number` | ✅ | Minutes of continuous failures before alerting |
| `reminders` | `object` | ❌ | Reminder notification configuration |
| `parallelRunFailureThreshold` | `object` | ❌ | Parallel run failure percentage threshold |

### Examples

<CodeGroup>

```ts Long Processes
// Good for batch jobs or slow services
const timeBasedAlert = AlertEscalationBuilder.timeBasedEscalation(
  15, // Alert after 15 minutes of failures
  { interval: 10, amount: 3 }, // 3 reminders, 10 minutes apart
  { enabled: false, percentage: 50 }
)

new ApiCheck('batch-job-check', {
  name: 'Batch Job Monitoring',
  frequency: Frequency.EVERY_5M,
  alertEscalationPolicy: timeBasedAlert,
  request: {
    method: 'GET',
    url: 'https://api.example.com/batch-status'
  }
})
```

```ts Environment Aware
const isProduction = process.env.NODE_ENV === 'production'

const alertPolicy = isProduction
  ? AlertEscalationBuilder.timeBasedEscalation(
      5, // Production: alert quickly after 5 minutes
      { interval: 5, amount: 5 },
      { enabled: true, percentage: 50 }
    )
  : AlertEscalationBuilder.timeBasedEscalation(
      30, // Staging: be more tolerant, 30 minutes
      { interval: 60, amount: 1 },
      { enabled: true, percentage: 80 }
    )

new ApiCheck('environment-aware-check', {
  name: `${isProduction ? 'Production' : 'Staging'} API Check`,
  alertEscalationPolicy: alertPolicy,
  request: {
    method: 'GET',
    url: `https://${isProduction ? 'api' : 'staging-api'}.example.com/health`
  }
})
```

</CodeGroup>

**Use cases**: Batch job monitoring, slow services, time-sensitive operations.
</ResponseField>

<ResponseField name="reminders" type="object">
Configure reminder notifications while an alert is active.

### Usage
```ts
reminders: {
  interval: 10, // Send reminder every 10 minutes
  amount: 5     // Send up to 5 reminders
}
```

### Parameters
| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `interval` | `number` | ✅ | - | Minutes between reminder notifications |
| `amount` | `number` | ✅ | - | Number of reminder notifications to send |

### Examples

<CodeGroup>

```ts No Reminders
// Alert once, no reminders
reminders: {
  interval: 5,
  amount: 0
}
```

```ts Frequent Reminders
// Aggressive reminder schedule
reminders: {
  interval: 5, // Every 5 minutes
  amount: 10   // Up to 10 reminders
}
```

```ts Conservative Reminders
// Occasional reminders to avoid spam
reminders: {
  interval: 30, // Every 30 minutes
  amount: 2     // Only 2 reminders
}
```

</CodeGroup>

**Use cases**: Alert fatigue prevention, escalation management, notification frequency control.
</ResponseField>

<ResponseField name="parallelRunFailureThreshold" type="object">
Configure threshold for checks running in parallel across multiple locations.

### Usage
```ts
parallelRunFailureThreshold: {
  enabled: true,
  percentage: 60 // Alert if 60% of parallel runs fail
}
```

### Parameters
| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `enabled` | `boolean` | ✅ | - | Whether to use parallel run failure threshold |
| `percentage` | `number` | ❌ | - | Percentage of parallel runs that must fail (10-100, in increments of 10) |

### Examples

<CodeGroup>

```ts Regional Redundancy
// Only alert if majority of regions fail
const regionalAlert = AlertEscalationBuilder.runBasedEscalation(
  2, // After 2 consecutive failures
  { interval: 10, amount: 3 },
  { enabled: true, percentage: 70 } // 70% of regions must fail
)

new ApiCheck('global-service-check', {
  name: 'Global Service Check',
  locations: ['us-east-1', 'us-west-2', 'eu-west-1', 'ap-southeast-1'],
  runParallel: true,
  alertEscalationPolicy: regionalAlert,
  request: {
    method: 'GET',
    url: 'https://global-api.example.com/health'
  }
})
```

```ts CDN Monitoring
// Alert if half of CDN edges are failing
const cdnAlert = AlertEscalationBuilder.runBasedEscalation(
  1, // Immediate on failure
  { interval: 5, amount: 2 },
  { enabled: true, percentage: 50 } // 50% of edges must fail
)

new UrlMonitor('cdn-availability', {
  name: 'CDN Edge Availability',
  locations: ['us-east-1', 'us-west-2', 'eu-west-1', 'ap-southeast-1'],
  runParallel: true,
  alertEscalationPolicy: cdnAlert,
  request: {
    url: 'https://cdn.example.com/health'
  }
})
```

```ts Disabled Threshold
// Don't use parallel run thresholds
parallelRunFailureThreshold: {
  enabled: false,
  percentage: 50 // Ignored when disabled
}
```

</CodeGroup>

**Use cases**: Multi-region monitoring, CDN availability, redundant service checking.
</ResponseField>

## Examples

<CodeGroup>

```ts Group-Level Policy
import { CheckGroupV2, AlertEscalationBuilder } from 'checkly/constructs'

const groupAlertPolicy = AlertEscalationBuilder.runBasedEscalation(
  3, // Alert after 3 consecutive failures
  { interval: 15, amount: 3 }, // 3 reminders, 15 minutes apart
  { enabled: true, percentage: 60 }
)

const monitoringGroup = new CheckGroupV2('monitoring-group', {
  name: 'Production Monitoring',
  alertEscalationPolicy: groupAlertPolicy, // Applies to all checks in group
  locations: ['us-east-1', 'eu-west-1'],
  runParallel: true
})

new ApiCheck('group-api-check', {
  name: 'API Check with Group Alert Policy',
  group: monitoringGroup, // Inherits alert policy from group
  request: {
    method: 'GET',
    url: 'https://api.example.com/endpoint'
  }
})
```

```ts Override Individual Check
// Individual check overrides group settings
new ApiCheck('override-alert-check', {
  name: 'Check with Override Alert Policy',
  group: groupWithAlertPolicy,
  alertEscalationPolicy: AlertEscalationBuilder.runBasedEscalation(
    1, // More aggressive than group setting
    { interval: 2, amount: 10 }
  ),
  request: {
    method: 'GET',
    url: 'https://api.example.com/endpoint'
  }
})
```

```ts Complex Regional Setup
// Different thresholds for different service tiers
const criticalServiceAlert = AlertEscalationBuilder.runBasedEscalation(
  1, // Immediate alert for critical services
  { interval: 2, amount: 10 }, // Frequent reminders
  { enabled: true, percentage: 30 } // Alert if any region has issues
)

const standardServiceAlert = AlertEscalationBuilder.runBasedEscalation(
  3, // Wait for 3 failures for standard services
  { interval: 15, amount: 3 }, // Less frequent reminders
  { enabled: true, percentage: 60 } // Alert if majority of regions fail
)

new ApiCheck('critical-payment-api', {
  name: 'Critical Payment API',
  alertEscalationPolicy: criticalServiceAlert,
  locations: ['us-east-1', 'us-west-2', 'eu-west-1'],
  runParallel: true,
  request: {
    method: 'GET',
    url: 'https://payment-api.example.com/health'
  }
})
```

</CodeGroup>

<Warning>
**Reminder Limits**: Be cautious with reminder settings. Too many reminders can lead to alert fatigue, while too few might cause important issues to be overlooked.
</Warning>

<Info>
**Parallel Run Thresholds**: Only use parallel run failure thresholds for checks that run in multiple locations simultaneously (`runParallel: true`).
</Info>

## Configuration Hierarchy

Alert escalation policies follow the same hierarchy as other check properties:

1. **Individual Check** (highest priority)
2. **Check Group**
3. **Project** (not supported at project level)

Individual check settings will always override group-level alert escalation policies.