---
title: 'Overview'
description: 'Learn how to use AI to control your Checkly monitoring.'
sidebarTitle: 'Overview'
keywords: ['mcp', 'ai', 'rules', 'generate checks', 'agents', 'context']
---

import AgentExamples from "/snippets/agent-example.mdx"

From the beginning, Checkly has bet on [Monitoring as Code](/concepts/monitoring-as-code) which lets you create and control your monitoring infrastructure entirely using code.

By default, [Checkly constructs](/constructs/overview) reflect all your monitoring properties.

```ts api.check.ts
import { ApiCheck, AssertionBuilder } from "checkly/constructs"

new ApiCheck("api-health-check", {
  name: "API Health Check",
  request: {
    url: "https://danube-web.shop/api/books",
    method: "GET",
    assertions: [
      AssertionBuilder.statusCode().equals(200),
    ],
  },
})
```

All your monitoring resources can be updated, tested and deployed via [the Checkly CLI](/cli/overview).

```bash
# test your monitoring configuration
npx checkly test

# deploy and update your monitoring setup
npx checkly deploy
```

**The Monitoring as Code workflow is by default AI-native** because LLMs are excellent at writing and editing Checkly constructs code and modern AI agents can execute CLI commands easily.

Provide the necessary Checkly context and let your AI agent of choice do the rest.

<AgentExamples />

## Add Checkly context to your AI agent conversation

Install [Checkly Skills](/integrations/ai/skills) or add the [Checkly Rules](/integrations/ai/rules) to your AI conversation to give your AI agent enough context to perform Checkly-related tasks.

<Columns cols={2}>
<Card title="Checkly Skills" href="/integrations/ai/skills" cta="Get started">
Let your agents pull in all required Checkly context on demand.
</Card>

<Card title="Checkly Rules" href="/integrations/ai/rules" cta="Get started">
Include the entire Checkly context in commands or documentation.
</Card>
</Columns>

### Skills vs Rules

**Use Skills** when your AI agent supports the [Agent Skills](https://agentskills.io) standard. Skills load context on demand, keeping your agent's context window lean until Checkly-related tasks arise. This is the recommended approach for compatible agents.

**Use Rules** when your agent doesn't support skills or when you want the Checkly context always available. Rules files are loaded at session start and provide consistent context throughout your conversation.


## Why is there no Checkly MCP server (yet)?

The MCP concept is often used to enable LLMs to interact with external systems. It acts as a bridge between the AI model and the target system, translating natural language commands into actionable API calls or code snippets.

**With Monitoring as Code, Checkly already provides a native way to control your monitoring infrastructure via code and the command line.**

Whether you need to create new resources or update existing ones, AI can write and update the necessary construct files and execute the Checkly CLI commands autonomously.

<Tip>
We are investigating additional AI-native workflows. [Let us know in the public roadmap](https://feedback.checklyhq.com/p/checkly-mcp) if you are interested in more agent-friendly integrations.
</Tip>
